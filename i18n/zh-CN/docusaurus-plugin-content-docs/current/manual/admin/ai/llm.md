---
sidebar_label: 大模型
sidebar_position: 2
---

# 大模型

## 概述

微语大模型功能允许您连接和管理各种AI大模型提供商的模型，支持云端API模型和本地Ollama模型，为您的业务提供强大的AI能力。

## 主要功能

- 多种大模型提供商支持（OpenAI、Anthropic Claude、MiniMax、讯飞星火、百度文心、阿里通义等）
- 本地Ollama模型管理与使用
- 模型导入和自定义配置
- 多版本模型管理

## 使用指南

### 大模型提供商管理

1. 在左侧导航菜单中进入"大模型"页面
2. 左侧列表显示所有已添加的大模型提供商
3. 点击提供商后，在右侧可查看该提供商下的模型列表

#### 添加新的大模型提供商

1. 点击左上角"+"按钮添加新的大模型提供商
2. 在弹出对话框中选择提供商类型
3. 填写API URL和API Key等必要信息
4. 点击"保存"完成添加

### 模型管理

每个大模型提供商下可以管理多个模型：

1. 在右侧提供商详情页，可以看到该提供商下的所有模型
2. 点击"添加模型"按钮添加新模型
3. 填写模型名称(用于接口调用)和昵称(便于记忆)
4. 点击"保存"完成添加

#### 导入模型

对于已配置好的提供商，可以直接导入其支持的模型：

1. 点击"导入模型"按钮查看可导入的模型列表
2. 选择需要导入的模型，点击确认
3. 系统会自动将选中的模型加入到当前提供商下

### Ollama本地模型管理

微语支持使用Ollama运行本地大模型，以下是Ollama模型的使用步骤：

#### 前置条件

1. 您需要在本地安装并启动Ollama服务
2. 确保Ollama服务可以正常访问

#### 管理Ollama模型

1. 从左侧列表选择"Ollama"提供商
2. 右侧会显示Ollama的当前状态和已安装的本地模型列表
3. 点击"远程模型库"按钮浏览可下载的模型

#### 下载和使用Ollama模型

1. 在远程模型库中浏览可用模型
2. 点击模型旁的"拉取"按钮下载模型（下载大型模型可能需要较长时间）
3. 下载完成后，模型会出现在本地模型列表中
4. 点击模型名称可以查看详细信息，包括参数大小、量化等级等

#### 模型版本管理

1. 点击模型名称后的"详情"按钮查看模型详情
2. 在模型详情页可以查看和管理不同版本的模型
3. 可以拉取特定版本的模型（如llama3:latest或llama3:8b等）

#### 删除Ollama模型

1. 在本地模型列表中，找到需要删除的模型
2. 点击该模型右侧的"删除"按钮
3. 确认删除操作后，系统将从Ollama中移除该模型

## 模型类型说明

微语支持多种类型的AI模型，每种类型用不同颜色标记：

- **对话模型**（蓝色）：用于聊天和文本生成
- **嵌入模型**（紫色）：用于生成文本嵌入向量
- **视觉模型**（绿色）：处理图像识别和分析
- **代码模型**（青色）：专注于代码生成和补全
- **推理模型**（橙色）：用于逻辑推理任务
- **文生图模型**（洋红色）：将文本描述转换为图像
- **图生文模型**（粉色）：分析图像生成文本描述
- **语音转文本模型**（火山色）：将语音转换为文本
- **文本转语音模型**（极客蓝）：将文本转换为语音
- **文生视频模型**（石灰色）：从文本描述生成视频
- **视频转文本模型**（金色）：从视频内容生成文本描述

## 最佳实践

1. **API密钥安全**：确保API密钥安全存储，定期更换密钥
2. **模型选择**：根据任务需求选择合适的模型，通用对话可使用通用模型，专业任务选择专业模型
3. **本地与云端结合**：对于敏感数据处理，可以使用本地Ollama模型；对于需要更高性能的场景，可以使用云端API
4. **版本管理**：关注模型版本更新，及时更新到性能更好的新版本
5. **资源优化**：针对Ollama本地模型，注意选择合适的量化版本平衡性能和资源占用

## 故障排除

1. **API连接失败**：检查API URL和API Key是否正确，确认网络连接是否正常
2. **Ollama无法访问**：确认本地Ollama服务是否正常运行，可通过刷新按钮重新检测状态
3. **模型下载失败**：检查网络连接，确保有足够的硬盘空间和稳定的网络环境
4. **模型运行缓慢**：考虑使用更小参数或更高量化级别的模型版本
